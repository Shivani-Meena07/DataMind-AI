"""
Documentation Generator

Generates comprehensive, human-readable database documentation
from the analyzed intelligence store.
"""

import os
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
from pathlib import Path

from datamind.core.intelligence_store import (
    IntelligenceStore,
    TableProfile,
    ColumnProfile,
    Relationship,
    DataQualityIssue,
    DataQualitySeverity,
    BusinessInsight,
    TableType,
    ColumnType,
)
from datamind.config import DataMindConfig, OutputFormat

logger = logging.getLogger(__name__)


class DocumentationGenerator:
    """
    Generates comprehensive database documentation.
    
    Output includes:
    - Executive Summary
    - Database Overview
    - Entity Descriptions
    - Relationship Diagrams (textual)
    - Data Quality Report
    - Sample Analytics Queries
    - Warnings & Caveats
    - Improvement Suggestions
    """
    
    def __init__(self, config: DataMindConfig):
        """
        Initialize the documentation generator.
        
        Args:
            config: DataMind configuration
        """
        self.config = config
        self.output_config = config.output
    
    def generate(self, store: IntelligenceStore) -> str:
        """
        Generate complete documentation.
        
        Args:
            store: Populated intelligence store
            
        Returns:
            Generated documentation as string
        """
        logger.info("Generating documentation...")
        
        sections = []
        
        # Title and metadata
        sections.append(self._generate_title(store))
        
        # Table of Contents
        sections.append(self._generate_toc())
        
        # Executive Summary
        sections.append(self._generate_executive_summary(store))
        
        # Database Overview
        sections.append(self._generate_database_overview(store))
        
        # Entity Descriptions
        sections.append(self._generate_entity_descriptions(store))
        
        # Relationship Analysis
        sections.append(self._generate_relationship_section(store))
        
        # Data Quality Report
        if self.output_config.include_data_quality:
            sections.append(self._generate_quality_report(store))
        
        # Business Use Cases
        sections.append(self._generate_use_cases_section(store))
        
        # Sample Queries
        if self.output_config.include_sample_queries:
            sections.append(self._generate_sample_queries(store))
        
        # Warnings & Caveats
        sections.append(self._generate_warnings_section(store))
        
        # Improvement Suggestions
        sections.append(self._generate_improvements_section(store))
        
        # Appendix
        sections.append(self._generate_appendix(store))
        
        document = "\n\n".join(sections)
        
        logger.info("Documentation generation complete.")
        return document
    
    def save(self, document: str, filename: str = "database_user_manual") -> str:
        """
        Save documentation to file.
        
        Args:
            document: Generated documentation
            filename: Base filename (without extension)
            
        Returns:
            Path to saved file
        """
        output_dir = Path(self.output_config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        extension = {
            OutputFormat.MARKDOWN: ".md",
            OutputFormat.HTML: ".html",
            OutputFormat.JSON: ".json",
        }.get(self.output_config.format, ".md")
        
        filepath = output_dir / f"{filename}{extension}"
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(document)
        
        logger.info(f"Documentation saved to: {filepath}")
        return str(filepath)
    
    def _generate_title(self, store: IntelligenceStore) -> str:
        """Generate document title and metadata."""
        db_name = store.database_name or "Database"
        timestamp = store.analysis_timestamp.strftime("%Y-%m-%d %H:%M")
        
        return f"""# ðŸ“˜ {db_name} - Database User Manual

**Generated by DataMind AI**  
**Analysis Date:** {timestamp}  
**Database Type:** {store.database_type or 'Unknown'}  
**Version:** {store.database_version or 'Unknown'}

---

> *This document was automatically generated by analyzing the database schema and data patterns. 
> All insights are derived directly from the database structure and contents.*

---"""
    
    def _generate_toc(self) -> str:
        """Generate table of contents."""
        return """## ðŸ“‘ Table of Contents

1. [Executive Summary](#executive-summary)
2. [Database Overview](#database-overview)
3. [Entity Descriptions](#entity-descriptions)
4. [Relationship Analysis](#relationship-analysis)
5. [Data Quality Report](#data-quality-report)
6. [Business Use Cases & KPIs](#business-use-cases--kpis)
7. [Sample Analytics Queries](#sample-analytics-queries)
8. [Warnings & Caveats](#warnings--caveats)
9. [Improvement Suggestions](#improvement-suggestions)
10. [Appendix](#appendix)

---"""
    
    def _generate_executive_summary(self, store: IntelligenceStore) -> str:
        """Generate executive summary section."""
        stats = store.get_statistics()
        
        summary = store.executive_summary or self._create_default_summary(store)
        
        return f"""## ðŸ“‹ Executive Summary

{summary}

### Quick Statistics

| Metric | Value |
|--------|-------|
| Total Tables | {stats['total_tables']} |
| Total Columns | {stats['total_columns']} |
| Total Records | {stats['total_rows']:,} |
| Relationships | {stats['total_relationships']} |
| Data Quality Score | {stats['overall_quality_score']:.1f}/100 |
| Critical Issues | {stats['critical_issues']} |
| Warning Issues | {stats['warning_issues']} |

---"""
    
    def _create_default_summary(self, store: IntelligenceStore) -> str:
        """Create default summary when LLM summary is not available."""
        stats = store.get_statistics()
        
        # Determine database purpose from table types
        fact_tables = [t for t, p in store.tables.items() if p.table_type == TableType.FACT]
        dim_tables = [t for t, p in store.tables.items() if p.table_type == TableType.DIMENSION]
        
        return f"""This database contains {stats['total_tables']} tables with approximately {stats['total_rows']:,} total records. 
The schema includes {len(fact_tables)} transaction/fact tables and {len(dim_tables)} dimension/reference tables, 
connected through {stats['total_relationships']} defined relationships.

The overall data quality score is {stats['overall_quality_score']:.1f}/100, with {stats['critical_issues']} critical 
issues and {stats['warning_issues']} warnings identified that may require attention."""
    
    def _generate_database_overview(self, store: IntelligenceStore) -> str:
        """Generate database overview section."""
        lines = [
            "## ðŸ—„ï¸ Database Overview",
            "",
            "### Table Classification",
            "",
            "| Table | Type | Rows | Columns | Description |",
            "|-------|------|------|---------|-------------|",
        ]
        
        # Sort tables by type for better organization
        sorted_tables = sorted(
            store.tables.items(),
            key=lambda x: (x[1].table_type.value, x[0])
        )
        
        for table_name, table in sorted_tables:
            type_emoji = {
                TableType.DIMENSION: "ðŸ“¦",
                TableType.FACT: "ðŸ“Š",
                TableType.BRIDGE: "ðŸ”—",
                TableType.AUDIT: "ðŸ“",
                TableType.CONFIGURATION: "âš™ï¸",
            }.get(table.table_type, "ðŸ“„")
            
            desc = (table.business_entity or table.business_description or "â€”")[:50]
            lines.append(
                f"| {table_name} | {type_emoji} {table.table_type.value} | "
                f"{table.row_count:,} | {table.column_count} | {desc} |"
            )
        
        lines.append("")
        lines.append("### Schema Legend")
        lines.append("")
        lines.append("- ðŸ“¦ **Dimension**: Reference/lookup tables containing descriptive attributes")
        lines.append("- ðŸ“Š **Fact**: Transaction/event tables containing measurable data")
        lines.append("- ðŸ”— **Bridge**: Junction tables resolving many-to-many relationships")
        lines.append("- ðŸ“ **Audit**: Logging and audit trail tables")
        lines.append("- âš™ï¸ **Configuration**: System configuration tables")
        lines.append("")
        lines.append("---")
        
        return "\n".join(lines)
    
    def _generate_entity_descriptions(self, store: IntelligenceStore) -> str:
        """Generate detailed entity descriptions."""
        lines = ["## ðŸ“š Entity Descriptions", ""]
        
        # Sort by dependency order if possible
        table_order = store.get_topological_order()
        
        for table_name in table_order:
            table = store.tables.get(table_name)
            if not table:
                continue
            
            lines.extend(self._generate_table_section(table, store))
            lines.append("")
        
        lines.append("---")
        return "\n".join(lines)
    
    def _generate_table_section(
        self, 
        table: TableProfile, 
        store: IntelligenceStore
    ) -> List[str]:
        """Generate documentation section for a single table."""
        lines = []
        
        # Table header
        type_badge = f"`{table.table_type.value}`"
        lines.append(f"### ðŸ“„ {table.name} {type_badge}")
        lines.append("")
        
        # Business description
        if table.business_entity:
            lines.append(f"**Business Entity:** {table.business_entity}")
            lines.append("")
        
        if table.business_description:
            lines.append(f"**Purpose:** {table.business_description}")
            lines.append("")
        
        if table.primary_users:
            lines.append(f"**Primary Users:** {table.primary_users}")
            lines.append("")
        
        if table.update_frequency:
            lines.append(f"**Update Frequency:** {table.update_frequency}")
            lines.append("")
        
        # Table stats
        lines.append(f"**Statistics:** {table.row_count:,} rows, {table.column_count} columns")
        lines.append("")
        
        # Column table
        lines.append("#### Columns")
        lines.append("")
        lines.append("| Column | Type | Nullable | Description |")
        lines.append("|--------|------|----------|-------------|")
        
        for col_name, col in table.columns.items():
            # Build column flags
            flags = []
            if col.is_primary_key:
                flags.append("ðŸ”‘ PK")
            if col.is_foreign_key:
                flags.append(f"ðŸ”— FKâ†’{col.references_table}")
            
            flag_str = f" ({', '.join(flags)})" if flags else ""
            nullable = "âœ“" if col.nullable else "âœ—"
            desc = (col.business_description or col.semantic_type.value)[:60]
            
            lines.append(f"| **{col_name}**{flag_str} | `{col.data_type}` | {nullable} | {desc} |")
        
        lines.append("")
        
        # Detailed column info (if available)
        has_detailed = any(
            col.business_relevance or col.common_usage 
            for col in table.columns.values()
        )
        
        if has_detailed:
            lines.append("#### Column Details")
            lines.append("")
            
            for col_name, col in table.columns.items():
                if col.business_relevance or col.common_usage:
                    lines.append(f"**{col_name}**")
                    if col.business_relevance:
                        lines.append(f"- *Relevance:* {col.business_relevance}")
                    if col.common_usage:
                        lines.append(f"- *Usage:* {col.common_usage}")
                    if col.sample_values:
                        samples = ", ".join(str(v) for v in col.sample_values[:5])
                        lines.append(f"- *Sample values:* {samples}")
                    lines.append("")
        
        # Quality warnings for this table
        table_issues = store.get_quality_issues_for_table(table.name)
        if table_issues:
            lines.append("#### âš ï¸ Data Quality Notes")
            lines.append("")
            for issue in table_issues[:5]:
                severity_icon = {
                    DataQualitySeverity.CRITICAL: "ðŸ”´",
                    DataQualitySeverity.WARNING: "ðŸŸ¡",
                    DataQualitySeverity.INFO: "ðŸ”µ",
                }.get(issue.severity, "âšª")
                lines.append(f"- {severity_icon} {issue.description}")
            lines.append("")
        
        return lines
    
    def _generate_relationship_section(self, store: IntelligenceStore) -> str:
        """Generate relationship analysis section."""
        lines = [
            "## ðŸ”— Relationship Analysis",
            "",
            "### Entity Relationship Diagram (Textual)",
            "",
            "```",
        ]
        
        # Generate ASCII-style diagram
        lines.extend(self._generate_text_diagram(store))
        
        lines.append("```")
        lines.append("")
        
        # Detailed relationships
        lines.append("### Relationship Details")
        lines.append("")
        
        for rel in store.relationships:
            cardinality_desc = {
                "1:1": "One-to-One",
                "1:N": "One-to-Many",
                "N:1": "Many-to-One",
                "N:M": "Many-to-Many",
            }.get(rel.cardinality, rel.cardinality)
            
            lines.append(f"#### {rel.source_table} â†’ {rel.target_table}")
            lines.append("")
            lines.append(f"- **Type:** {cardinality_desc} ({rel.cardinality})")
            lines.append(f"- **Source Column:** {', '.join(rel.source_columns)}")
            lines.append(f"- **Target Column:** {', '.join(rel.target_columns)}")
            
            if rel.business_description:
                lines.append(f"- **Description:** {rel.business_description}")
            
            if rel.data_flow_description:
                lines.append(f"- **Data Flow:** {rel.data_flow_description}")
            
            lines.append("")
        
        # Dependency hierarchy
        lines.append("### Data Dependency Hierarchy")
        lines.append("")
        lines.append("Tables listed in load order (dependencies first):")
        lines.append("")
        
        for i, table in enumerate(store.get_topological_order(), 1):
            table_profile = store.tables.get(table)
            type_str = f" ({table_profile.table_type.value})" if table_profile else ""
            lines.append(f"{i}. {table}{type_str}")
        
        lines.append("")
        lines.append("---")
        
        return "\n".join(lines)
    
    def _generate_text_diagram(self, store: IntelligenceStore) -> List[str]:
        """Generate a text-based relationship diagram."""
        lines = []
        
        # Group tables by type
        dim_tables = [t for t, p in store.tables.items() if p.table_type == TableType.DIMENSION]
        fact_tables = [t for t, p in store.tables.items() if p.table_type == TableType.FACT]
        other_tables = [t for t, p in store.tables.items() 
                       if p.table_type not in (TableType.DIMENSION, TableType.FACT)]
        
        if dim_tables:
            lines.append("DIMENSION TABLES:")
            for t in dim_tables:
                lines.append(f"  [{t}]")
            lines.append("      |")
            lines.append("      v")
        
        if fact_tables:
            lines.append("FACT TABLES:")
            for t in fact_tables:
                refs = [r.target_table for r in store.get_outgoing_relationships(t)]
                refs_str = f" --> {', '.join(refs)}" if refs else ""
                lines.append(f"  [{t}]{refs_str}")
        
        if other_tables:
            lines.append("")
            lines.append("OTHER TABLES:")
            for t in other_tables:
                lines.append(f"  [{t}]")
        
        return lines
    
    def _generate_quality_report(self, store: IntelligenceStore) -> str:
        """Generate data quality report section."""
        lines = [
            "## ðŸ“Š Data Quality Report",
            "",
            f"**Overall Quality Score: {store.overall_quality_score:.1f}/100**",
            "",
        ]
        
        # Score interpretation
        if store.overall_quality_score >= 90:
            lines.append("âœ… **Excellent** - Data quality is very good with minimal issues.")
        elif store.overall_quality_score >= 70:
            lines.append("ðŸŸ¡ **Good** - Data quality is acceptable but some issues need attention.")
        elif store.overall_quality_score >= 50:
            lines.append("ðŸŸ  **Fair** - Several data quality issues require remediation.")
        else:
            lines.append("ðŸ”´ **Poor** - Significant data quality problems exist.")
        
        lines.append("")
        
        # Issues by severity
        critical = [i for i in store.quality_issues if i.severity == DataQualitySeverity.CRITICAL]
        warnings = [i for i in store.quality_issues if i.severity == DataQualitySeverity.WARNING]
        info = [i for i in store.quality_issues if i.severity == DataQualitySeverity.INFO]
        
        if critical:
            lines.append("### ðŸ”´ Critical Issues")
            lines.append("")
            for issue in critical:
                col_str = f".{issue.column}" if issue.column else ""
                lines.append(f"- **{issue.table}{col_str}**: {issue.description}")
                if issue.recommendation:
                    lines.append(f"  - *Recommendation:* {issue.recommendation}")
            lines.append("")
        
        if warnings:
            lines.append("### ðŸŸ¡ Warnings")
            lines.append("")
            for issue in warnings[:10]:  # Limit to 10
                col_str = f".{issue.column}" if issue.column else ""
                lines.append(f"- **{issue.table}{col_str}**: {issue.description}")
            if len(warnings) > 10:
                lines.append(f"- *... and {len(warnings) - 10} more warnings*")
            lines.append("")
        
        if info:
            lines.append("### ðŸ”µ Informational")
            lines.append("")
            for issue in info[:5]:  # Limit to 5
                col_str = f".{issue.column}" if issue.column else ""
                lines.append(f"- **{issue.table}{col_str}**: {issue.description}")
            lines.append("")
        
        # NULL analysis
        lines.append("### NULL Value Analysis")
        lines.append("")
        lines.append("| Table | Column | NULL % | Affected Rows |")
        lines.append("|-------|--------|--------|---------------|")
        
        null_issues = []
        for table_name, table in store.tables.items():
            for col_name, col in table.columns.items():
                if col.null_percentage > 0.05:  # More than 5%
                    null_issues.append((
                        table_name, col_name, 
                        col.null_percentage, col.null_count
                    ))
        
        null_issues.sort(key=lambda x: x[2], reverse=True)
        
        for table, col, pct, count in null_issues[:15]:
            lines.append(f"| {table} | {col} | {pct:.1%} | {count:,} |")
        
        lines.append("")
        lines.append("---")
        
        return "\n".join(lines)
    
    def _generate_use_cases_section(self, store: IntelligenceStore) -> str:
        """Generate business use cases section."""
        lines = [
            "## ðŸ’¡ Business Use Cases & KPIs",
            "",
        ]
        
        # Group insights by category
        questions = [i for i in store.insights if i.category == "BusinessQuestion"]
        kpis = [i for i in store.insights if i.category == "KPI"]
        use_cases = [i for i in store.insights if i.category == "UseCase"]
        
        if questions:
            lines.append("### Business Questions This Database Can Answer")
            lines.append("")
            for q in questions:
                tables = ", ".join(q.related_tables) if q.related_tables else "Multiple tables"
                lines.append(f"- **{q.description}**")
                lines.append(f"  - *Tables:* {tables}")
            lines.append("")
        
        if kpis:
            lines.append("### Suggested KPIs")
            lines.append("")
            for kpi in kpis:
                lines.append(f"#### {kpi.title}")
                lines.append(f"{kpi.description}")
                if kpi.related_tables:
                    lines.append(f"- *Source tables:* {', '.join(kpi.related_tables)}")
                lines.append("")
        
        if use_cases:
            lines.append("### Analytics Use Cases by Domain")
            lines.append("")
            for uc in use_cases:
                lines.append(f"#### {uc.title}")
                lines.append(f"{uc.description}")
                if uc.related_tables:
                    lines.append(f"- *Tables:* {', '.join(uc.related_tables)}")
                lines.append("")
        
        if not (questions or kpis or use_cases):
            lines.append("*Use cases will be generated when LLM inference is enabled.*")
            lines.append("")
        
        lines.append("---")
        return "\n".join(lines)
    
    def _generate_sample_queries(self, store: IntelligenceStore) -> str:
        """Generate sample analytics queries section."""
        lines = [
            "## ðŸ” Sample Analytics Queries",
            "",
            "The following SQL queries demonstrate common analytics patterns for this database.",
            "",
        ]
        
        # Generate some basic queries based on schema
        queries = self._create_sample_queries(store)
        
        for i, q in enumerate(queries, 1):
            lines.append(f"### Query {i}: {q['title']}")
            lines.append("")
            lines.append(q['description'])
            lines.append("")
            lines.append("```sql")
            lines.append(q['sql'])
            lines.append("```")
            lines.append("")
        
        lines.append("---")
        return "\n".join(lines)
    
    def _create_sample_queries(self, store: IntelligenceStore) -> List[Dict]:
        """Create sample SQL queries based on schema."""
        queries = []
        
        # Find tables suitable for common queries
        fact_tables = [t for t, p in store.tables.items() if p.table_type == TableType.FACT]
        dim_tables = [t for t, p in store.tables.items() if p.table_type == TableType.DIMENSION]
        
        # Basic row count query
        if store.tables:
            first_table = list(store.tables.keys())[0]
            queries.append({
                'title': 'Row Count by Table',
                'description': 'Get the number of records in each table.',
                'sql': f"""-- Count records in each table
SELECT '{first_table}' as table_name, COUNT(*) as row_count FROM "{first_table}"
-- UNION ALL for other tables..."""
            })
        
        # Find a good fact table for analytics
        for table_name in fact_tables[:1]:
            table = store.tables[table_name]
            
            # Find timestamp column
            timestamp_col = None
            for col_name, col in table.columns.items():
                if col.semantic_type == ColumnType.TIMESTAMP:
                    timestamp_col = col_name
                    break
            
            if timestamp_col:
                queries.append({
                    'title': f'Daily {table_name} Trends',
                    'description': f'Analyze {table_name} trends over time.',
                    'sql': f"""-- Daily trend analysis
SELECT 
    DATE("{timestamp_col}") as date,
    COUNT(*) as count
FROM "{table_name}"
GROUP BY DATE("{timestamp_col}")
ORDER BY date DESC
LIMIT 30;"""
                })
        
        # Join query if relationships exist
        if store.relationships:
            rel = store.relationships[0]
            queries.append({
                'title': f'Join {rel.source_table} with {rel.target_table}',
                'description': f'Combine data from related tables.',
                'sql': f"""-- Join related tables
SELECT 
    s.*,
    t.*
FROM "{rel.source_table}" s
INNER JOIN "{rel.target_table}" t 
    ON s."{rel.source_columns[0]}" = t."{rel.target_columns[0]}"
LIMIT 100;"""
            })
        
        # Aggregation query
        for table_name in fact_tables[:1]:
            table = store.tables[table_name]
            
            # Find metric columns
            metric_cols = [
                col_name for col_name, col in table.columns.items()
                if col.semantic_type == ColumnType.METRIC
            ]
            
            if metric_cols:
                queries.append({
                    'title': f'Aggregate Metrics from {table_name}',
                    'description': 'Calculate summary statistics.',
                    'sql': f"""-- Aggregate metrics
SELECT 
    COUNT(*) as total_records,
    AVG("{metric_cols[0]}") as avg_{metric_cols[0]},
    SUM("{metric_cols[0]}") as total_{metric_cols[0]},
    MIN("{metric_cols[0]}") as min_{metric_cols[0]},
    MAX("{metric_cols[0]}") as max_{metric_cols[0]}
FROM "{table_name}";"""
                })
        
        return queries
    
    def _generate_warnings_section(self, store: IntelligenceStore) -> str:
        """Generate warnings and caveats section."""
        lines = [
            "## âš ï¸ Warnings & Caveats",
            "",
        ]
        
        # Standard caveats
        lines.append("### Analysis Limitations")
        lines.append("")
        lines.append("- This documentation was generated through automated analysis and may not capture all business context.")
        lines.append("- Semantic interpretations are inferred from column names, data types, and patterns. Some inferences may be incorrect.")
        lines.append("- Data quality metrics are based on a sample and may not reflect the entire dataset.")
        lines.append("- Relationship cardinalities are estimated based on uniqueness patterns.")
        lines.append("")
        
        # Custom warnings from analysis
        if store.warnings_and_caveats:
            lines.append("### Analysis-Specific Warnings")
            lines.append("")
            for warning in store.warnings_and_caveats:
                lines.append(f"- {warning}")
            lines.append("")
        
        # Isolated tables warning
        isolated = store.get_isolated_tables()
        if isolated:
            lines.append("### Isolated Tables")
            lines.append("")
            lines.append("The following tables have no detected relationships and may be orphaned or require manual relationship definition:")
            lines.append("")
            for table in isolated:
                lines.append(f"- {table}")
            lines.append("")
        
        lines.append("---")
        return "\n".join(lines)
    
    def _generate_improvements_section(self, store: IntelligenceStore) -> str:
        """Generate improvement suggestions section."""
        lines = [
            "## ðŸš€ Improvement Suggestions",
            "",
        ]
        
        if store.improvement_suggestions:
            lines.append("### Schema & Data Improvements")
            lines.append("")
            for suggestion in store.improvement_suggestions:
                lines.append(f"- {suggestion}")
            lines.append("")
        
        # Standard recommendations
        lines.append("### General Recommendations")
        lines.append("")
        
        # Check for missing PKs
        tables_without_pk = [
            t for t, p in store.tables.items() 
            if not p.has_primary_key
        ]
        if tables_without_pk:
            lines.append(f"- **Add primary keys** to: {', '.join(tables_without_pk[:5])}")
        
        # Check for high null columns
        high_null = sum(
            1 for t in store.tables.values() 
            for c in t.columns.values() 
            if c.null_percentage > 0.5
        )
        if high_null:
            lines.append(f"- **Address data sparsity**: {high_null} columns have >50% NULL values")
        
        # Indexing recommendations
        lines.append("- **Review indexing**: Consider adding indexes on frequently queried foreign key columns")
        lines.append("- **Documentation**: Maintain this document alongside schema changes")
        lines.append("- **Data validation**: Implement constraints to prevent data quality issues at the source")
        
        lines.append("")
        lines.append("---")
        return "\n".join(lines)
    
    def _generate_appendix(self, store: IntelligenceStore) -> str:
        """Generate appendix with technical details."""
        lines = [
            "## ðŸ“Ž Appendix",
            "",
            "### A. Complete Column Reference",
            "",
        ]
        
        # Full schema reference
        for table_name, table in store.tables.items():
            lines.append(f"#### {table_name}")
            lines.append("")
            lines.append("| Column | Type | PK | FK | Nullable | Unique% | Null% |")
            lines.append("|--------|------|----|----|----------|---------|-------|")
            
            for col_name, col in table.columns.items():
                pk = "âœ“" if col.is_primary_key else ""
                fk = col.references_table or ""
                nullable = "âœ“" if col.nullable else ""
                unique_pct = f"{col.uniqueness_ratio:.1%}" if col.uniqueness_ratio else "â€”"
                null_pct = f"{col.null_percentage:.1%}" if col.null_percentage else "0%"
                
                lines.append(
                    f"| {col_name} | {col.data_type} | {pk} | {fk} | "
                    f"{nullable} | {unique_pct} | {null_pct} |"
                )
            
            lines.append("")
        
        # Generation metadata
        lines.append("### B. Generation Metadata")
        lines.append("")
        lines.append(f"- **Generated:** {store.analysis_timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"- **Database Type:** {store.database_type}")
        lines.append(f"- **Tables Analyzed:** {len(store.tables)}")
        lines.append(f"- **Relationships Found:** {len(store.relationships)}")
        lines.append(f"- **Quality Issues:** {len(store.quality_issues)}")
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("*End of Document*")
        
        return "\n".join(lines)
